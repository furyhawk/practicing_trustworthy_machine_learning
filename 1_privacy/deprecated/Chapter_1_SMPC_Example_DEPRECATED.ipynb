{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-RLwt28IRgF7"
      },
      "source": [
        "# Chapter 1: SMPC Example (Deprecated)\n",
        "\n",
        "| Chapter  | Colab   | Kaggle          | Gradient      | Studio Lab             | Binder             |\n",
        "|:---------|:--------|:----------------|:--------------|:-----------------------|:-------------------|\n",
        "| [Chapter 1: SMPC Example](1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb)                         | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb)       | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb)       | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb)       | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb)       | [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/matthew-mcateer/practicing_trustworthy_machine_learning/HEAD?urlpath=https%3A%2F%2Fgithub.com%2Fmatthew-mcateer%2Fpracticing_trustworthy_machine_learning%2Fblob%2Fmain%2F1_privacy%2Fdeprecated%2FChapter_1_SMPC_Example_DEPRECATED.ipynb)              |\n",
        "\n",
        "<!--\n",
        "Originally found on GitHub at https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb\n",
        "-->\n",
        "\n",
        "\n",
        "The following is heavily based on an OpenMined tutorial written by [Ayoub Benaissa - Twitter: @y0uben11](https://twitter.com/y0uben11)\n",
        "\n",
        "```text\n",
        "This tutorial is currently optimized for running in a Docker container on a local machine.\n",
        "\n",
        "The tutorial that inspired this previously could run on multiple Google Colab instances.\n",
        "\n",
        "However, after Colab changed the accessibility of multiple runtimes, this is no longer the case.\n",
        "\n",
        "Specific instructions for the new Colab version will be added in the future.\n",
        "```\n",
        "\n",
        "To run this example, clone the [OpenMined/Pygrid](https://github.com/OpenMined/PyGrid/commit/048be4ac52a53b5ca947b920e41de9a9e76a532a) repo and start the two GridNodes by running\n",
        "\n",
        "```bash\n",
        "cd\n",
        "cd apps/node\n",
        "./run.sh --id ID --port 3000 --start_local_db\n",
        "```\n",
        "\n",
        "and\n",
        "\n",
        "```bash\n",
        "cd\n",
        "cd apps/node\n",
        "./run.sh --id ID --port 3001 --start_local_db\n",
        "```\n",
        "\n",
        "in separate terminals.\n",
        "\n",
        "Alternatively, you can use the colab notebooks\n",
        "\n",
        "- [SMPC_Mock_Node_1.ipynb](1_privacy/deprecated/Chapter_1_SMPC_Mock_Node_1.ipynb)\n",
        "- [SMPC_Mock_Node_2.ipynb](1_privacy/deprecated/Chapter_1_SMPC_Mock_Node_2.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4IGp3E3RjU0",
        "outputId": "10b549ef-dcb3-4382-8d0c-8701a2c59e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch not installed. Installing...\n",
            "\u001b[K     |████████████████████████████████| 735.5 MB 17 kB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.10 requires torchvision>=0.8.2, which is not installed.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hTorch version:  1.8.0\n",
            "\u001b[K     |████████████████████████████████| 433 kB 22.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 484 kB 98.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 67.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 26.0 MB 89.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 70.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 66 kB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 87.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 449 kB 70.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.6 MB 553 kB/s \n",
            "\u001b[K     |████████████████████████████████| 126 kB 97.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 23 kB/s \n",
            "\u001b[K     |████████████████████████████████| 200 kB 105.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 7.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.0 MB 40.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 36.7 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 71 kB 10.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 82.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 6.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 8.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 82.0 MB/s \n",
            "\u001b[?25h  Building wheel for openmined.threepio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for phe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.4.0 which is incompatible.\n",
            "tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.25 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "google-colab 1.0.0 requires notebook~=5.7.16, but you have notebook 5.7.8 which is incompatible.\n",
            "google-colab 1.0.0 requires requests>=2.23.0, but you have requests 2.22.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=6.0.4, but you have tornado 4.5.3 which is incompatible.\n",
            "fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.4.0 which is incompatible.\n",
            "fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.5.0 which is incompatible.\n",
            "distributed 2022.2.0 requires tornado>=6.0.3; python_version >= \"3.8\", but you have tornado 4.5.3 which is incompatible.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\n",
            "bokeh 2.3.3 requires tornado>=5.1, but you have tornado 4.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 245 kB 26.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 73.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 33.8 MB 542 kB/s \n",
            "\u001b[K     |██████████████████████████████  | 834.1 MB 79.7 MB/s eta 0:00:01tcmalloc: large alloc 1147494400 bytes == 0x39940000 @  0x7f3744042615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |███████████████████████████████ | 862.6 MB 79.7 MB/s eta 0:00:01"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 890.2 MB 5.9 kB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 24.3 MB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 117 kB 98.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 78.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 849 kB 92.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 557.1 MB 12 kB/s \n",
            "\u001b[K     |████████████████████████████████| 317.1 MB 35 kB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
            "syft 0.2.9 requires scipy~=1.4.1, but you have scipy 1.9.3 which is incompatible.\n",
            "syft 0.2.9 requires torch~=1.4.0, but you have torch 1.13.0 which is incompatible.\n",
            "syft 0.2.9 requires torchvision~=0.5.0, but you have torchvision 0.14.0 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 58 kB 76 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title PySyft & PyTorch Setup { display-mode: \"form\" }\n",
        "!pip -qq uninstall torch torchvision --y\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "except:\n",
        "    print(\"PyTorch not installed. Installing...\")\n",
        "    !pip -qq install torch==1.8.0\n",
        "\n",
        "    import torch\n",
        "    print(\"Torch version: \", torch.__version__ )\n",
        "    assert torch.__version__=='1.8.0', \"torch version is not 1.8.0, the version needed to make this run correctly\"\n",
        "\n",
        "!pip -qq install syft==0.2.9\n",
        "!pip -qq install crypten\n",
        "!pip -qq install loguru\n",
        "#!pip -qq install --upgrade --force-reinstall lz4\n",
        "#!pip -qq install --upgrade --force-reinstall websocket\n",
        "#!pip -qq install --upgrade --force-reinstall websockets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e_jjjflCe6kA"
      },
      "outputs": [],
      "source": [
        "!pip -qq install watermark\n",
        "%load_ext watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "KW-1TC4JfPRw",
        "outputId": "8c5ddd7f-f8c2-49ca-c401-f985b0b90ca8"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2f271d4edb42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'watermark'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-a \"Practicing Trustworthy machine Learning\" -u -d -v -m -p syft'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2312\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2314\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2315\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-118>\u001b[0m in \u001b[0;36mwatermark\u001b[0;34m(self, line)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/watermark/magic.py\u001b[0m in \u001b[0;36mwatermark\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'watermark_self'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mformatted_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwatermark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatermark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/watermark/watermark.py\u001b[0m in \u001b[0;36mwatermark\u001b[0;34m(author, email, github_username, website, current_date, datename, current_time, iso8601, timezone, updated, custom_time, python, packages, conda, hostname, machine, githash, gitrepo, gitbranch, watermark, iversions, watermark_self, globals_)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_pyversions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'packages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'packages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conda'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_conda_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/watermark/watermark.py\u001b[0m in \u001b[0;36m_get_packages\u001b[0;34m(pkgs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     return {package: _get_package_version(package)\n\u001b[0m\u001b[1;32m    215\u001b[0m             for package in packages}\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/watermark/watermark.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     return {package: _get_package_version(package)\n\u001b[0m\u001b[1;32m    215\u001b[0m             for package in packages}\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/watermark/watermark.py\u001b[0m in \u001b[0;36m_get_package_version\u001b[0;34m(pkg_name)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mpkg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sklearn\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mimported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"not installed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/syft/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# This import statement is strictly here to trigger registration of syft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# tensor types inside hook_args.py.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpreters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnative\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m from syft.generic.frameworks.hook.hook_args import (\n\u001b[1;32m      6\u001b[0m     \u001b[0mregister_ambiguous_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhook_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverloaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpreters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaillier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPaillierTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/syft/generic/frameworks/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mframework_packages\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/syft/generic/frameworks/types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdependency_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrypten_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mcrypten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mframework_packages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"crypten\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrypten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/crypten/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrypten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrypten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpc\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcrypten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrypten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/crypten/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistances\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCosineSimilarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBCELoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL1Loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m from .module import (\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/crypten/nn/distances.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/crypten/nn/loss.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/crypten/nn/module.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrypten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_helper\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msym_help\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcrypten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_adaptive_pool2d_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/onnx/symbolic_helper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Monkey-patch graph manipulation methods on Graph, used for the ONNX symbolics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from torch.onnx import (  # noqa: F401\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0m_constants\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0m_deprecation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/onnx/_patch_torch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Import utils to get _params_dict because it is a global that is accessed by c++ code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_globals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGLOBALS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_beartype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m from torch.onnx import (  # noqa: F401\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0m_constants\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0m_deprecation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/onnx/symbolic_caffe2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msymbolic_helper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_opset9\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopset9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjit_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/onnx/symbolic_opset9.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Monkey-patch graph manipulation methods on Graph, used for the ONNX symbolics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m from torch.onnx import (  # noqa: F401\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0m_constants\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0m_patch_torch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/onnx/_type_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mJitScalarType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLEX64\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_C_onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorProtoDataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLEX64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mJitScalarType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLEX128\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_C_onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorProtoDataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLEX128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0mJitScalarType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBFLOAT16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_C_onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorProtoDataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBFLOAT16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0mJitScalarType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNDEFINED\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_C_onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorProtoDataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNDEFINED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mJitScalarType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLEX32\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_C_onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorProtoDataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNDEFINED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'torch._C._onnx.TensorProtoDataType' has no attribute 'BFLOAT16'"
          ]
        }
      ],
      "source": [
        "%watermark -a \"Practicing Trustworthy machine Learning\" -u -d -v -m -p syft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqyAB6XpfPJF"
      },
      "outputs": [],
      "source": [
        "%watermark -a \"Practicing Trustworthy machine Learning\" -u -d -v -m -p syft,crypten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1OZulcPfN7P"
      },
      "outputs": [],
      "source": [
        "%watermark -a \"Practicing Trustworthy machine Learning\" -u -d -v -m -p syft,crypten,loguru,torch,torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmpN-OEvYH3a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0uInwhfRiYE"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import crypten\n",
        "import syft\n",
        "from time import time\n",
        "from syft.frameworks.crypten.context import run_multiworkers\n",
        "from syft.grid.clients.data_centric_fl_client import DataCentricFLClient\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6f0BtjwRiJU"
      },
      "outputs": [],
      "source": [
        "!wget \"https://raw.githubusercontent.com/facebookresearch/CrypTen/b1466440bde4db3e6e1fcb1740584d35a16eda9e/tutorials/mnist_utils.py\" -O \"mnist_utils.py\"\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ox-ueitRiGd"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python \"mnist_utils.py\" --option features --reduced 100 --binary\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5CfSXuIdXNf"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "torch.set_num_threads(1)\n",
        "hook = syft.TorchHook(torch)\n",
        "\n",
        "#from syft.workers.node_client import NodeClient # No module named 'syft.workers.node_client'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-eJtdjqRiDj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define an example network\n",
        "class ExampleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExampleNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=0)\n",
        "        self.fc1 = nn.Linear(16 * 12 * 12, 100)\n",
        "        self.fc2 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = F.relu(out)\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(-1, 16 * 12 * 12)\n",
        "        out = self.fc1(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAU6KKfCRiAa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Syft workers\n",
        "print(\"[%] Connecting to workers ...\")\n",
        "ALICE = DataCentricFLClient(hook, \"ws://localhost:3000\")\n",
        "BOB = DataCentricFLClient(hook, \"ws://localhost:3001\")\n",
        "print(\"[+] Connected to workers\")\n",
        "\n",
        "print(\"[%] Sending labels and training data ...\")\n",
        "# Prepare and send labels\n",
        "label_eye = torch.eye(2)\n",
        "labels = torch.load(\"/tmp/train_labels.pth\")\n",
        "labels = labels.long()\n",
        "labels_one_hot = label_eye[labels]\n",
        "labels_one_hot.tag(\"labels\")\n",
        "al_ptr = labels_one_hot.send(ALICE)\n",
        "bl_ptr = labels_one_hot.send(BOB)\n",
        "\n",
        "# Prepare and send training data\n",
        "alice_train = torch.load(\"/tmp/alice_train.pth\").tag(\"alice_train\")\n",
        "at_ptr = alice_train.send(ALICE)\n",
        "bob_train = torch.load(\"/tmp/bob_train.pth\").tag(\"bob_train\")\n",
        "bt_ptr = bob_train.send(BOB)\n",
        "\n",
        "print(\"[+] Data ready\")\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXRa1d6bXmzU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize model\n",
        "dummy_input = torch.empty(1, 1, 28, 28)\n",
        "pytorch_model = ExampleNet()\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e86ff--bXmxL"
      },
      "outputs": [],
      "source": [
        "\n",
        "@run_multiworkers([ALICE, BOB], master_addr=\"127.0.0.1\", model=pytorch_model, dummy_input=dummy_input)\n",
        "def run_encrypted_training():\n",
        "    rank = crypten.communicator.get().get_rank()\n",
        "    # Load the labels\n",
        "    worker = syft.frameworks.crypten.get_worker_from_rank(rank)\n",
        "    labels_one_hot = worker.search(\"labels\")[0]\n",
        "    # Load data:\n",
        "    x_alice_enc = crypten.load(\"alice_train\", 0)\n",
        "    x_bob_enc = crypten.load(\"bob_train\", 1)\n",
        "    # Combine the feature sets: identical to Tutorial 3\n",
        "    x_combined_enc = crypten.cat([x_alice_enc, x_bob_enc], dim=2)\n",
        "    # Reshape to match the network architecture\n",
        "    x_combined_enc = x_combined_enc.unsqueeze(1)\n",
        "    # model is sent from the master worker\n",
        "    model.encrypt()\n",
        "    # Set train mode\n",
        "    model.train()\n",
        "    # Define a loss function\n",
        "    loss = crypten.nn.MSELoss()\n",
        "    # Define training parameters\n",
        "    learning_rate = 0.001\n",
        "    num_epochs = 2\n",
        "    batch_size = 10\n",
        "    num_batches = x_combined_enc.size(0) // batch_size\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "        # Print once for readability\n",
        "        if rank == 0:\n",
        "            print(f\"Epoch {i} in progress:\")\n",
        "            pass\n",
        "\n",
        "        for batch in range(num_batches):\n",
        "            # define the start and end of the training mini-batch\n",
        "            start, end = batch * batch_size, (batch + 1) * batch_size\n",
        "            # construct AutogradCrypTensors out of training examples / labels\n",
        "            x_train = x_combined_enc[start:end]\n",
        "            y_batch = labels_one_hot[start:end]\n",
        "            y_train = crypten.cryptensor(y_batch, requires_grad=True)\n",
        "            # perform forward pass:\n",
        "            output = model(x_train)\n",
        "            loss_value = loss(output, y_train)\n",
        "            # set gradients to \"zero\"\n",
        "            model.zero_grad()\n",
        "            # perform backward pass:\n",
        "            loss_value.backward()\n",
        "            # update parameters\n",
        "            model.update_parameters(learning_rate)\n",
        "            # Print progress every batch:\n",
        "            batch_loss = loss_value.get_plain_text()\n",
        "            if rank == 0:\n",
        "                print(f\"\\tBatch {(batch + 1)} of {num_batches} Loss {batch_loss.item():.4f}\")\n",
        "\n",
        "    model.decrypt()\n",
        "    # printed contain all the printed strings during training\n",
        "    return printed, model\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdB3NAMiXmuj"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"[%] Starting computation\")\n",
        "func_ts = time()\n",
        "result = run_encrypted_training()\n",
        "func_te = time()\n",
        "print(f\"[+] run_encrypted_training() took {int(func_te - func_ts)}s\")\n",
        "printed = result[0][0]\n",
        "model = result[0][1]\n",
        "print(printed)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi0MejkqXmr4"
      },
      "outputs": [],
      "source": [
        "\n",
        "cp = syft.VirtualWorker(hook=hook, id=\"cp\")\n",
        "model.fix_prec()\n",
        "model.share(ALICE, BOB, crypto_provider=cp)\n",
        "print(model)\n",
        "print(list(model.parameters())[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT_nkoTkXmo7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit ('3.9.0')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0 (default, Dec 11 2020, 03:26:52) \n[Clang 12.0.0 (clang-1200.0.32.21)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b6b7e97e50c754c7aee36d85160e6764033ec8a20165f676e018446c78d531c2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
